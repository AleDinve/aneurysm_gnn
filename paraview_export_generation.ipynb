{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import torch_geometric as pyg\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch_geometric.utils import to_undirected\n",
    "import networkx as nx\n",
    "from utils import dataset_gen, sublists\n",
    "import seaborn as sns\n",
    "from model import GNN\n",
    "import os\n",
    "from torch_geometric.loader import DataLoader\n",
    "from IPython.display import clear_output\n",
    "from utils import minmaxscaler\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WSS - dataset generation for Paraview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 'WSS'\n",
    "\n",
    "it = 0\n",
    "conv_type = 'gtr'\n",
    "input_size = 7 # dataset features: Time, Press_SA, Press_abd, FlowRate, coord(x), coord(y), coord(z)\n",
    "hidden_size = 32\n",
    "num_layers = 5\n",
    "#for num_layers in list_layers:\n",
    "output_size = 1\n",
    "task_type = 'interp'\n",
    "param_type = 'layers'\n",
    "log_name = '_'.join([conv_type,'hid', str(hidden_size),'nl',str(num_layers), 'loss'])\n",
    "log_path = task_type+ '/' + '_'.join([param_type,index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNN(input_size,hidden_size,output_size,num_layers,conv_type=conv_type,device=device)\n",
    "model.load_state_dict(torch.load(log_path+'/'+log_name + str(it)+'.pt', map_location=torch.device('cpu')))\n",
    "perc = 75\n",
    "dataset = dataset_gen(perc,[index])\n",
    "num_nodes = dataset[0].num_nodes\n",
    "T = len(dataset)\n",
    "loader = DataLoader(dataset, batch_size = T, shuffle=False)\n",
    "pred = torch.zeros((T,num_nodes))\n",
    "y = torch.zeros((T,num_nodes))\n",
    "for i, data in enumerate(loader):\n",
    "    y = data.y.reshape((T,num_nodes)).detach().numpy()\n",
    "    pred = model(data.x, data.edge_index).reshape((T,num_nodes)).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAWSS - dataset generation for Paraview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/alessio/Desktop/Postdoc/Aneurysm_GNN/results/paraview_export_generation.ipynb Cella 6\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alessio/Desktop/Postdoc/Aneurysm_GNN/results/paraview_export_generation.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m data[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,:] \u001b[39m=\u001b[39m data[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,:]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alessio/Desktop/Postdoc/Aneurysm_GNN/results/paraview_export_generation.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m TAWSS \u001b[39m=\u001b[39m dt \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mabs(data), axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alessio/Desktop/Postdoc/Aneurysm_GNN/results/paraview_export_generation.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m pred \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alessio/Desktop/Postdoc/Aneurysm_GNN/results/paraview_export_generation.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m pred[\u001b[39m0\u001b[39m,:] \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alessio/Desktop/Postdoc/Aneurysm_GNN/results/paraview_export_generation.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m pred[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,:] \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "dt = 1/T\n",
    "data_copy = y.detach().numpy()\n",
    "data_copy[0,:] = data[0,:]/2\n",
    "data_copy[-1,:] = data[-1,:]/2\n",
    "TAWSS = dt * np.sum(np.abs(data), axis = 0)\n",
    "pred_copy = pred.detach().numpy()\n",
    "pred_copy[0,:] /= 2\n",
    "pred_copy[-1,:] /=2\n",
    "TAWSSp = dt * np.sum(np.abs(pred), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_tawss_folder= 'export_TAWSS/'\n",
    "os.makedirs(exp_tawss_folder,exist_ok=True)\n",
    "torch.save(TAWSS.reshape((1,-1)), exp_tawss_folder + 'TAWSS.pt')\n",
    "torch.save(TAWSSp.reshape((1,-1)), exp_tawss_folder+ 'TAWSS_pred.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4g/4249y1xd42d75jmm55xxl99m0000gn/T/ipykernel_9172/3463704888.py:2: RuntimeWarning: divide by zero encountered in divide\n",
      "  rel_error = np.abs(y - pred)/np.abs(y)\n"
     ]
    }
   ],
   "source": [
    "abs_error = np.abs(y - pred)\n",
    "rel_error = np.abs(y - pred)/np.abs(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = '_'.join(['export',index+'/'])\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "torch.save(y, save_folder+'_'.join(['original', 'data', str(perc)]))\n",
    "savefile_name = [task_type, param_type, str(num_layers), str(hidden_size), str(perc)+'.pt']\n",
    "torch.save(pred, save_folder+ '_'.join(['prediction'] + savefile_name) )\n",
    "torch.save(abs_error, save_folder+ '_'.join(['abs','error'] + savefile_name))\n",
    "torch.save(rel_error, save_folder+'_'.join(['rel','error'] + savefile_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OSI - dataset generation for Paraview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 'OSI'\n",
    "\n",
    "it = 0\n",
    "conv_type = 'gtr'\n",
    "input_size = 7 # dataset features: Time, Press_SA, Press_abd, FlowRate, coord(x), coord(y), coord(z)\n",
    "hidden_size = 32\n",
    "num_layers = 4\n",
    "#for num_layers in list_layers:\n",
    "output_size = 1\n",
    "task_type = 'interp'\n",
    "param_type = 'layers'\n",
    "log_name = '_'.join([conv_type,'hid', str(hidden_size),'nl',str(num_layers), 'loss'])\n",
    "log_path = task_type+ '/' + '_'.join([param_type,index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNN(input_size,hidden_size,output_size,num_layers,conv_type=conv_type,device=device)\n",
    "model.load_state_dict(torch.load(log_path+'/'+log_name + str(it)+'.pt', map_location=torch.device('cpu')))\n",
    "perc = 75\n",
    "dataset = dataset_gen(perc,[index])\n",
    "num_nodes = dataset[0].num_nodes\n",
    "T = len(dataset)\n",
    "loader = DataLoader(dataset, batch_size = 1, shuffle=False)\n",
    "pred = torch.zeros((T,num_nodes))\n",
    "y = torch.zeros((T,num_nodes))\n",
    "for i, data in enumerate(loader):\n",
    "    y[i,:] = data.y.squeeze()\n",
    "    pred[i,:] = model(data.x, data.edge_index).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = '_'.join(['export',index+'/'])\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "torch.save(y, save_folder+'_'.join(['original', 'data', str(perc)+'.pt']))\n",
    "savefile_name = [task_type, param_type, str(num_layers), str(hidden_size), str(perc)+'.pt']\n",
    "torch.save(pred, save_folder+ '_'.join(['prediction'] + savefile_name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2177"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_id",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
